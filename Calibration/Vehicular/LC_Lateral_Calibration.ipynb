{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99475f-598c-437e-bf0c-59068af486cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### find lane change -+ 10 secs\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Example data file paths\n",
    "datasets = {\n",
    "    #\"df395\": \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\lateral_align\\\\I395-final-run-index.csv\",\n",
    "    \"df294l1\": \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\lateral_align\\\\df294l1-aligned.csv\",\n",
    "    #\"df9094\": \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\lateral_align\\\\df9094-aligned.csv\",\n",
    "    \"df294l2\": \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\lateral_align\\\\df294l2-aligned.csv\"\n",
    "}\n",
    "\n",
    "save_dir = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\lateral_align\\\\\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # Ensure save directory exists\n",
    "\n",
    "# Combined output file\n",
    "output_csv_path = os.path.join(save_dir, \"combined_lane_change_data.csv\")\n",
    "all_lane_change_data = []  # List to collect data across all datasets\n",
    "lane_change_counter = 0  # Counter for assigning unique lane change IDs\n",
    "\n",
    "# Iterate through datasets\n",
    "for df_key, df_path in datasets.items():\n",
    "    # Load and preprocess the dataset\n",
    "    df = pd.read_csv(df_path)\n",
    "    df = df.sort_values(by=['run-index', 'time'])\n",
    "    df['time'] = df['time'].round(1)\n",
    "\n",
    "    # Process each unique run-index\n",
    "    for run_index in df['run-index'].unique():\n",
    "        run_data = df[df['run-index'] == run_index].copy()  # Use `.copy()` to create an independent DataFrame\n",
    "        \n",
    "        # Detect lane changes by comparing consecutive rows for each vehicle\n",
    "        run_data.loc[:, 'lane-change'] = run_data.groupby('ID')['lane-kf'].diff().fillna(0).ne(0)  # Detect lane changes per vehicle\n",
    "        \n",
    "        # Get rows where a lane change occurred\n",
    "        lane_change_events = run_data[run_data['lane-change']]\n",
    "        \n",
    "        for _, event in lane_change_events.iterrows():\n",
    "            lane_change_counter += 1  # Increment lane change ID counter\n",
    "            vehicle_id = event['ID']  # ID of the vehicle performing the lane change\n",
    "            lane_change_time = event['time']  # Time of lane change\n",
    "            \n",
    "            # Extract 5 seconds before and after the lane change for this specific vehicle\n",
    "            vehicle_data = run_data[run_data['ID'] == vehicle_id]  # Filter data for this vehicle\n",
    "            surrounding_data = vehicle_data[\n",
    "                (vehicle_data['time'] >= lane_change_time - 20) &\n",
    "                (vehicle_data['time'] <= lane_change_time + 20)\n",
    "            ].copy()  # Use `.copy()` to avoid warnings\n",
    "            \n",
    "            # Add dataset, ID, and run-index columns to the surrounding data\n",
    "            surrounding_data.loc[:, 'dataset'] = df_key\n",
    "            surrounding_data.loc[:, 'run-index'] = run_index\n",
    "            surrounding_data.loc[:, 'ID'] = vehicle_id\n",
    "            surrounding_data.loc[:, 'LC_ID'] = lane_change_counter  # Assign lane change ID\n",
    "            \n",
    "            # Calculate relative time\n",
    "            surrounding_data.loc[:, 'time-relative'] = surrounding_data['time'] - lane_change_time\n",
    "            \n",
    "            # Select relevant columns, including lane-kf and time-relative\n",
    "            relevant_data = surrounding_data[\n",
    "                ['dataset', 'run-index', 'ID', 'LC_ID', 'time', 'time-relative', 'xloc-kf', 'yloc-kf', 'speed-kf', 'acceleration-kf', 'lane-kf', 'type-most-common']\n",
    "            ]\n",
    "            \n",
    "            # Append to the combined list\n",
    "            all_lane_change_data.append(relevant_data)\n",
    "\n",
    "# Combine all data into a single DataFrame and save to a CSV file\n",
    "if all_lane_change_data:\n",
    "    combined_df = pd.concat(all_lane_change_data, ignore_index=True)\n",
    "    combined_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Saved combined lane change data to {output_csv_path}\")\n",
    "else:\n",
    "    print(\"No lane changes were detected in the datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d83f3b-c7b2-4c7d-89e7-87e64f9c371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Path to the combined lane change data\n",
    "input_csv_path = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\lateral_align\\\\combined_lane_change_data.csv\"\n",
    "plot_save_dir = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\Plots\\\\\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)  # Ensure save directory exists\n",
    "\n",
    "# Load the data\n",
    "lane_change_data = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Iterate through each dataset, run-index, and ID\n",
    "for dataset in lane_change_data['dataset'].unique():\n",
    "    dataset_data = lane_change_data[lane_change_data['dataset'] == dataset]\n",
    "    \n",
    "    for run_index in dataset_data['run-index'].unique():\n",
    "        run_data = dataset_data[dataset_data['run-index'] == run_index]\n",
    "        \n",
    "        for vehicle_id in run_data['ID'].unique():\n",
    "            vehicle_data = run_data[run_data['ID'] == vehicle_id]\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(vehicle_data['time'], vehicle_data['yloc-kf'], marker='o', linestyle='-', label='Y Location')\n",
    "            #plt.axvline(x=0, color='r', linestyle='--', label='Lane Change Event')\n",
    "            plt.xlabel('Time Relative to Lane Change (s)')\n",
    "            plt.ylabel('Y Location')\n",
    "            plt.title(f'Dataset: {dataset} | Run Index: {run_index} | ID: {vehicle_id}')\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            \n",
    "            # Save the plot\n",
    "            plot_filename = f\"{dataset}_run{run_index}_ID{vehicle_id}.png\"\n",
    "            plt.show()\n",
    "            #plt.savefig(os.path.join(plot_save_dir, plot_filename))\n",
    "            plt.close()\n",
    "\n",
    "print(f\"Plots saved to {plot_save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b78f28-6670-4eea-bd81-619278888258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Paths\n",
    "input_csv_path = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\lateral_align\\\\combined_lane_change_data.csv\"\n",
    "plot_save_dir = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\Fitted_Curves\\\\\"\n",
    "results_csv_path = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\Fitted_Curves\\\\Fitted_Models_Results.csv\"\n",
    "os.makedirs(plot_save_dir, exist_ok=True)  # Ensure save directory exists\n",
    "\n",
    "# Load the data\n",
    "lane_change_data = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Define polynomial fitting functions\n",
    "def cubic_fit(x, a, b, c, d):\n",
    "    return a * x**3 + b * x**2 + c * x + d\n",
    "\n",
    "def quintic_fit(x, a, b, c, d, e, f):\n",
    "    return a * x**5 + b * x**4 + c * x**3 + d * x**2 + e * x + f\n",
    "\n",
    "# Store results in a DataFrame\n",
    "results = []\n",
    "\n",
    "# Iterate through each unique LC_ID\n",
    "for lc_id in lane_change_data['LC_ID'].unique():\n",
    "    lc_data = lane_change_data[lane_change_data['LC_ID'] == lc_id]\n",
    "    \n",
    "    # Extract metadata\n",
    "    dataset = lc_data['dataset'].iloc[0]\n",
    "    run_index = lc_data['run-index'].iloc[0]\n",
    "    veh_id = lc_data['ID'].iloc[0]\n",
    "\n",
    "    # Extract time, lateral position, and speed\n",
    "    time_relative = lc_data['time-relative'].values\n",
    "    yloc = lc_data['yloc-kf'].values\n",
    "    speed = lc_data['speed-kf'].values  # Extract speed values\n",
    "    \n",
    "    # Compute derivatives for velocity and acceleration\n",
    "    velocity = np.gradient(yloc, time_relative)\n",
    "    acceleration = np.gradient(velocity, time_relative)\n",
    "    \n",
    "    # Smooth velocity and acceleration\n",
    "    velocity_smooth = savgol_filter(velocity, 7, 2)\n",
    "    acceleration_smooth = savgol_filter(acceleration, 7, 2)\n",
    "    \n",
    "    # Detect lane change start and end\n",
    "    vel_threshold = 0.25 * np.max(np.abs(velocity_smooth))  # 25% of peak velocity\n",
    "    start_idx = np.where(np.abs(velocity_smooth) > vel_threshold)[0][0]\n",
    "    end_idx = np.where(np.abs(velocity_smooth) > vel_threshold)[0][-1]\n",
    "    \n",
    "    # Extract lane change duration data\n",
    "    lane_change_time = time_relative[start_idx:end_idx+1]\n",
    "\n",
    "    lane_change_duration = time_relative[end_idx] - time_relative[start_idx]\n",
    "\n",
    "    # Skip this lane change if the duration is less than 15 seconds\n",
    "    if lane_change_duration < 1:\n",
    "        print(f\"Skipping LC_ID={lc_id} due to insufficient duration: {lane_change_duration:.2f} seconds.\")\n",
    "        continue\n",
    "\n",
    "    if lane_change_duration > 11:\n",
    "        print(f\"Skipping LC_ID={lc_id} due to insufficient duration: {lane_change_duration:.2f} seconds.\")\n",
    "        continue\n",
    "    \n",
    "    lane_change_yloc = yloc[start_idx:end_idx+1]\n",
    "    \n",
    "    # Fit cubic and quintic curves\n",
    "    popt_cubic, _ = curve_fit(cubic_fit, lane_change_time, lane_change_yloc)\n",
    "    popt_quintic, _ = curve_fit(quintic_fit, lane_change_time, lane_change_yloc)\n",
    "    \n",
    "    # Generate predictions for error calculation\n",
    "    y_cubic_pred = cubic_fit(lane_change_time, *popt_cubic)\n",
    "    y_quintic_pred = quintic_fit(lane_change_time, *popt_quintic)\n",
    "    \n",
    "    # Compute error metrics\n",
    "    rmse_cubic = np.sqrt(mean_squared_error(lane_change_yloc, y_cubic_pred))\n",
    "    mae_cubic = mean_absolute_error(lane_change_yloc, y_cubic_pred)\n",
    "    r2_cubic = r2_score(lane_change_yloc, y_cubic_pred)\n",
    "    \n",
    "    rmse_quintic = np.sqrt(mean_squared_error(lane_change_yloc, y_quintic_pred))\n",
    "    mae_quintic = mean_absolute_error(lane_change_yloc, y_quintic_pred)\n",
    "    r2_quintic = r2_score(lane_change_yloc, y_quintic_pred)\n",
    "    \n",
    "    # Extract speed at the start and end of the lane change\n",
    "    speed_start = speed[start_idx]\n",
    "    speed_end = speed[end_idx]\n",
    "    \n",
    "    # Find the index where time-relative is closest to zero (lane change start time)\n",
    "    closest_to_zero_idx = np.argmin(np.abs(time_relative))  # Index where time-relative is closest to 0\n",
    "    speed_at_lane_change = speed[closest_to_zero_idx]  # Speed at time-relative = 0\n",
    "    \n",
    "    # Save results including speed at the start, end, and at time-relative = 0\n",
    "    results.append({\n",
    "        \"dataset\": dataset,\n",
    "        \"run-index\": run_index,\n",
    "        \"ID\": veh_id,\n",
    "        \"LC_ID\": lc_id,\n",
    "        \"start_time\": time_relative[start_idx],\n",
    "        \"end_time\": time_relative[end_idx],\n",
    "        \"duration\": time_relative[end_idx] - time_relative[start_idx],\n",
    "        \"cubic_a\": popt_cubic[0],\n",
    "        \"cubic_b\": popt_cubic[1],\n",
    "        \"cubic_c\": popt_cubic[2],\n",
    "        \"cubic_d\": popt_cubic[3],\n",
    "        \"cubic_rmse\": rmse_cubic,\n",
    "        \"cubic_mae\": mae_cubic,\n",
    "        \"cubic_r2\": r2_cubic,\n",
    "        \"quintic_a\": popt_quintic[0],\n",
    "        \"quintic_b\": popt_quintic[1],\n",
    "        \"quintic_c\": popt_quintic[2],\n",
    "        \"quintic_d\": popt_quintic[3],\n",
    "        \"quintic_e\": popt_quintic[4],\n",
    "        \"quintic_f\": popt_quintic[5],\n",
    "        \"quintic_rmse\": rmse_quintic,\n",
    "        \"quintic_mae\": mae_quintic,\n",
    "        \"quintic_r2\": r2_quintic,\n",
    "        \"speed_start\": speed_start,\n",
    "        \"speed_end\": speed_end,\n",
    "        \"speed_at_lane_change\": speed_at_lane_change  # Add new column for speed at time-relative = 0\n",
    "    })\n",
    "    \n",
    "    # Create a 3x1 subplot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "\n",
    "    # Generate smooth time series for plotting\n",
    "    time_smooth = np.linspace(lane_change_time.min(), lane_change_time.max(), 100)\n",
    "    yloc_cubic_fit = cubic_fit(time_smooth, *popt_cubic)\n",
    "    yloc_quintic_fit = quintic_fit(time_smooth, *popt_quintic)\n",
    "\n",
    "    # Plot lateral position with fits\n",
    "    axes[0].scatter(time_relative, yloc, label='Original Data', color='gray', alpha=0.6)\n",
    "    axes[0].plot(time_smooth, yloc_cubic_fit, label=f'Cubic Fit (R²={r2_cubic:.2f})', linestyle='--')\n",
    "    axes[0].plot(time_smooth, yloc_quintic_fit, label=f'Quintic Fit (R²={r2_quintic:.2f})', linestyle='-')\n",
    "    axes[0].axvline(time_relative[start_idx], color='r', linestyle='--', label='Start of Lane Change')\n",
    "    axes[0].axvline(time_relative[end_idx], color='g', linestyle='--', label='End of Lane Change')\n",
    "    axes[0].set_ylabel('Lateral Position')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid()\n",
    "    \n",
    "    # Plot velocity\n",
    "    axes[1].plot(time_relative, velocity, label='Velocity (Raw)', linestyle='--', alpha=0.6)\n",
    "    axes[1].plot(time_relative, velocity_smooth, label='Velocity (Smoothed)', linestyle='-')\n",
    "    axes[1].axvline(time_relative[start_idx], color='r', linestyle='--')\n",
    "    axes[1].axvline(time_relative[end_idx], color='g', linestyle='--')\n",
    "    axes[1].set_ylabel('Lateral Velocity')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid()\n",
    "    \n",
    "    # Plot acceleration\n",
    "    axes[2].plot(time_relative, acceleration, label='Acceleration (Raw)', linestyle='--', alpha=0.6)\n",
    "    axes[2].plot(time_relative, acceleration_smooth, label='Acceleration (Smoothed)', linestyle='-')\n",
    "    axes[2].axvline(time_relative[start_idx], color='r', linestyle='--')\n",
    "    axes[2].axvline(time_relative[end_idx], color='g', linestyle='--')\n",
    "    axes[2].set_xlabel('Time Relative to Lane Change (s)')\n",
    "    axes[2].set_ylabel('Lateral Acceleration')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid()\n",
    "\n",
    "    # Construct filename\n",
    "    filename = f\"LC_{dataset}_Run{run_index}_ID{veh_id}_LC{lc_id}.png\"\n",
    "    filepath = os.path.join(plot_save_dir, filename)\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filepath)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Plot saved as: {filename}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {results_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1d255-6cc3-47f1-87f0-b71f0bb6d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter r2 < 0.5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Load the CSV file\n",
    "results_csv_path = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\Fitted_Curves\\\\Fitted_Models_Results.csv\"\n",
    "results_df = pd.read_csv(results_csv_path)\n",
    "\n",
    "# Filter data where quintic_r2 >= 0.5\n",
    "filtered_results_df = results_df[results_df[\"quintic_r2\"] >= 0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e396f-4b85-4fde-b802-9593b45b71c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### duration fit\n",
    "\n",
    "# Extract relevant columns\n",
    "durations = filtered_results_df[\"duration\"].values\n",
    "speeds_at_lane_change = filtered_results_df[\"speed_start\"].values\n",
    "\n",
    "# Number of observations after filtering\n",
    "num_observations = len(durations)\n",
    "print(f\"Number of observations after filtering: {num_observations}\")\n",
    "\n",
    "# Check if we have enough data to fit a model\n",
    "if num_observations > 1:\n",
    "    # Define a linear function for fitting\n",
    "    def linear_fit(x, m, b):\n",
    "        return m * x + b\n",
    "\n",
    "    # Fit the linear model\n",
    "    popt, _ = curve_fit(linear_fit, speeds_at_lane_change, durations)\n",
    "    slope, intercept = popt\n",
    "\n",
    "    print(f\"Fitted Linear Model: duration = {slope:.4f} * speed_at_lane_change + {intercept:.4f}\")\n",
    "\n",
    "    # Generate values for plotting\n",
    "    speed_range = np.linspace(min(speeds_at_lane_change), max(speeds_at_lane_change), 100)\n",
    "    duration_fit = linear_fit(speed_range, *popt)\n",
    "\n",
    "    # Plot the data and the fitted line\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(speeds_at_lane_change, durations, label=\"Data Points\", alpha=0.6)\n",
    "    plt.plot(speed_range, duration_fit, color=\"red\", label=f\"Fitted Line\")\n",
    "    plt.xlabel(\"Speed at Lane Change\")\n",
    "    plt.ylabel(\"Duration of Lane Change\")\n",
    "    plt.title(\"Linear Fit: Duration vs. Speed at Lane Change\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    filename = f\"Duration_R2Plot.png\"\n",
    "    filepath = os.path.join(plot_save_dir, filename)\n",
    "    plt.savefig(filepath)\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough data points to fit a model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294b907-b7b6-4890-8833-da1100c5f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_csv_path = \"C:\\\\Users\\\\Pedram\\\\Desktop\\\\PEDRAM - DO NOT TOUCH\\\\PT_IDM\\\\Fitted_Curves\\\\Fitted_Models_Results.csv\"\n",
    "results_df = pd.read_csv(results_csv_path)\n",
    "results_df = results_df[results_df[\"quintic_r2\"] >= 0.85]\n",
    "\n",
    "# Compute the mean of the quintic parameters\n",
    "quintic_params = ['quintic_a', 'quintic_b', 'quintic_c', 'quintic_d', 'quintic_e', 'quintic_f']\n",
    "mean_quintic_params = results_df[quintic_params].mean()\n",
    "\n",
    "# Report the mean values of the quintic polynomial parameters\n",
    "print(\"Mean Quintic Polynomial Parameters:\")\n",
    "print(mean_quintic_params)\n",
    "\n",
    "# Plot the distribution of the quintic polynomial parameters with percentile-based bins\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate(quintic_params):\n",
    "    # Get the parameter data\n",
    "    data = results_df[param]\n",
    "    \n",
    "    # Calculate the 5th and 95th percentiles\n",
    "    data_5th = np.percentile(data, 5)\n",
    "    data_95th = np.percentile(data, 95)\n",
    "    \n",
    "    # Define the bins: range from the 5th to the 95th percentile\n",
    "    bin_edges = np.linspace(data_5th, data_95th, 12)  # 8 bins (9 edges)\n",
    "    \n",
    "    # Plot histogram\n",
    "    axes[i].hist(data, bins=bin_edges, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f\"Distribution of {param}\")\n",
    "    axes[i].set_xlabel(param)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = f\"Parameter_R2Plot.png\"\n",
    "filepath = os.path.join(plot_save_dir, filename)\n",
    "plt.savefig(filepath)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of errors (RMSE, MAE) and R² with percentile-based bins\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# RMSE\n",
    "rmse_data = results_df['quintic_rmse']\n",
    "rmse_5th, rmse_95th = np.percentile(rmse_data, 5), np.percentile(rmse_data, 95)\n",
    "rmse_bin_edges = np.linspace(rmse_5th, rmse_95th, 12)\n",
    "axes[0].hist(rmse_data, bins=rmse_bin_edges, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title(\"Distribution of RMSE\")\n",
    "axes[0].set_xlabel('RMSE')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# MAE\n",
    "mae_data = results_df['quintic_mae']\n",
    "mae_5th, mae_95th = np.percentile(mae_data, 5), np.percentile(mae_data, 95)\n",
    "mae_bin_edges = np.linspace(mae_5th, mae_95th, 12)\n",
    "axes[1].hist(mae_data, bins=mae_bin_edges, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title(\"Distribution of MAE\")\n",
    "axes[1].set_xlabel('MAE')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "# R²\n",
    "r2_data = results_df['quintic_r2']\n",
    "r2_5th, r2_95th = np.percentile(r2_data, 5), np.percentile(r2_data, 95)\n",
    "r2_bin_edges = np.linspace(r2_5th, r2_95th, 12)\n",
    "axes[2].hist(r2_data, bins=r2_bin_edges, color='lightblue', edgecolor='black', alpha=0.7)\n",
    "axes[2].set_title(\"Distribution of R²\")\n",
    "axes[2].set_xlabel('R²')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = f\"Manouver_R2Plot.png\"\n",
    "filepath = os.path.join(plot_save_dir, filename)\n",
    "plt.savefig(filepath)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca7fea-cd9c-42eb-8123-1122ef577377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
