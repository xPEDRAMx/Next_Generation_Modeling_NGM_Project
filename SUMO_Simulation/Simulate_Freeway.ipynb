{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3bb5c-ff86-449f-ade0-dfd9d0c846b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import traci\n",
    "import sumolib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from sumolib import checkBinary\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import ray\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca44ebc-89ad-4f55-87ec-bf23f6de1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check env\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    raise EnvironmentError(\"Please declare environment variable 'SUMO_HOME'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d34e7-459d-4603-ace0-b867278e948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model folder for driving behavior\n",
    "model_folder=\"model_params/\"\n",
    "\n",
    "# read driving behavior models\n",
    "\n",
    "PT_param_data={0: pd.read_csv(model_folder+\"merged_PT_S.csv\"),\n",
    "                1: pd.read_csv(model_folder+\"merged_PT_A.csv\"),\n",
    "                   2: pd.read_csv(model_folder+\"merged_PT_L.csv\")\n",
    "                  }\n",
    "# IDM by vehicle type\n",
    "IDM_param_data={0: pd.read_csv(model_folder+\"merged_IDM_S.csv\"),\n",
    "                   1: pd.read_csv(model_folder+\"merged_IDM_A.csv\"),\n",
    "                   2: pd.read_csv(model_folder+\"merged_IDM_L.csv\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084eaeb8-dda7-490b-974d-8785ec214904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization function for all dataset\n",
    "# Note: the pickle files for next lanes are needed because Sumo cannot auytomatically detect the downstream lanes for customized models\n",
    "\n",
    "def initialize():\n",
    "    od_demand={} # the demands are stored as dictionaries of dictionary\n",
    "    if site==\"I90_94\":\n",
    "        # the names of input and output edges\n",
    "        in_names={1:\"main_in\", 2:\"on1\"}\n",
    "        out_names={1:\"off1\",2:\"off2\", 3:\"off3\", 4:\"off4\", 5:\"main_I90_out\", 6:\"main_I94_out\" }\n",
    "        downstream_outs={1:{1,2,3,4,5,6}, 2:{2,3,4,5,6}} # make sure that the exist is downstream of the entrance\n",
    "        # define edges as in sumo (can be changes in the future for an easier name)\n",
    "        in_edges={1:\"124471132\", 2:\"24521704#3.24\"}\n",
    "        out_edges={1:\"24306156\",2:\"24521700#0\", 3:\"27878350\", 4:\"27862401\", 5:\"380664935\", 6:\"907236679\" }\n",
    "        # user defined demand\n",
    "        # edges where MLC are made, and the directions\n",
    "        in_MLCs={\"124471132\":{}, \"24521704#3.24\":{\"121980283\":1}}\n",
    "        out_MLCs={\"24306156\":{}, \"24521700#0\":{}, \"27878350\":{}, \"27862401\":{}, \"380664935\":{}, \"907236679\":{}}\n",
    "        with open('configs/next_lanes_I90_94.pickle', 'rb') as handle:\n",
    "            next_lanes_dict = pickle.load(handle)\n",
    "        \n",
    "    elif site==\"I294\":\n",
    "        in_names={1:\"main_in\", 2:\"on1\", 3:\"on2\", 4:\"on3\"}\n",
    "        out_names={1:\"off1\", 2:\"off2\", 3:\"main_out\"}\n",
    "        in_edges={1:\"992387151#1\", 2:\"38878546.568\", 3:\"31144126.151\", 4:\"24067152.262\"}\n",
    "        out_edges={1:\"24067154\", 2:\"24067155\", 3:\"377623249#1-AddedOnRampEdge\"}\n",
    "        downstream_outs={1:{1,2,3}, 2:{1,2,3}, 3:{3}, 4:{3} }\n",
    "        \n",
    "        in_MLCs={\"61857431#1\":{}, \"61857388\":{\"121980283\":1}, \"24067978\":{}, \"38878546.568\":{}, \"31144126.151\":{}, \"24067152.262\":{}}\n",
    "        out_MLCs={\"33726629\":{},\"24067154\":{}, \"24067155\":{}, \"377623249#1\":{}}\n",
    "        \n",
    "        with open('configs/next_lanes_I294.pickle', 'rb') as handle:\n",
    "            next_lanes_dict = pickle.load(handle)\n",
    "    \n",
    "    elif site==\"I395\":\n",
    "        in_names={1: \"main_in\", 2:\"on1\"}\n",
    "        out_names={1: \"off1\", 2:\"main_out\"}\n",
    "        in_edges={1:\"6063187-AddedOffRampEdge\", 2:\"297204299\"}\n",
    "        out_edges={1:\"397355152\", 2:\"121980283.9\"}\n",
    "        downstream_outs={1:{1,2}, 2:{2} }\n",
    "        \n",
    "        in_MLCs={\"6063187-AddedOffRampEdge\":{}, \"297204299\":{\"121980283\":-1}} # for each origin what \n",
    "        out_MLCs={\"397355152\":{\"6063187-AddedOffRampEdge\":-1}, \"121980283.9\":{}}\n",
    "        \n",
    "        with open('configs/next_lanes_I395.pickle', 'rb') as handle:\n",
    "            next_lanes_dict = pickle.load(handle)\n",
    "\n",
    "    # Defines the dlow rate for od demand\n",
    "    # here we are assuming the flow between on-ramps and off-ramps are the same\n",
    "    # Also the same flow for \n",
    "    # \n",
    "    for in_idx in in_names:\n",
    "        od_demand[in_idx]={}\n",
    "        in_name=in_names[in_idx]\n",
    "        for out_idx in out_names:\n",
    "            out_name=out_names[out_idx]\n",
    "            if not out_idx in downstream_outs[in_idx]:\n",
    "                od_demand[in_idx][out_idx]=0 #if the offramp is upstream of the on ramp\n",
    "            elif (\"main\" in in_name) and (\"main\" in out_name):\n",
    "                od_demand[in_idx][out_idx]=flow_main\n",
    "            elif ((\"main\" in in_name) and ( not \"main\" in out_name)):\n",
    "                od_demand[in_idx][out_idx]=flow_main_to_ramp\n",
    "            elif ((not \"main\" in in_name) and (\"main\" in out_name)):\n",
    "                od_demand[in_idx][out_idx]=flow_ramp_to_main\n",
    "            else:\n",
    "                od_demand[in_idx][out_idx]=flow_ramp_to_ramp\n",
    "            print(\"From \" + in_name+\" to \"+out_name+\": \", od_demand[in_idx][out_idx], \"veh/hr\" )\n",
    "\n",
    "\n",
    "    all_edges=[]\n",
    "    # Load the XML file into a format readable by sumo\n",
    "    parsed_data = ET.parse('network_structure/'+site+'.net.xml')\n",
    "    root = parsed_data.getroot()\n",
    "    \n",
    "    print(f\"Root tag: {root.tag}, Root attributes: {root.attrib}\")\n",
    "    \n",
    "    # Iterate through elements to get the set of edges\n",
    "    for edge in root.findall(\".//edge\"):\n",
    "        all_edges.append(edge.attrib['id'])\n",
    "        \n",
    "    return od_demand, all_edges, in_edges, out_edges, 0, 0, next_lanes_dict\n",
    "\n",
    "def generate_vehicles(trial=None):\n",
    "    # first define dictionaries for generation times and all od pairs\n",
    "    \n",
    "    all_generation_times={}\n",
    "    origins=[]\n",
    "    destinations=[]\n",
    "    gen_times=[]\n",
    "    \n",
    "    for in_idx in od_demand:\n",
    "        in_edge=in_edges[in_idx]\n",
    "        all_generation_times[in_edge]={}\n",
    "        for out_idx in od_demand[in_idx]:\n",
    "            out_edge=out_edges[out_idx]\n",
    "            demand_rate=od_demand[in_idx][out_idx]\n",
    "            if demand_rate>0:\n",
    "                # if non-zero demand, then the arrival of vehicles is assumed to be poisson\n",
    "                generation_times=np.cumsum(np.maximum(np.random.exponential(3600/demand_rate, 100000), min_hw))\n",
    "                generation_times=generation_times[(generation_times>=min_t) & (generation_times<=max_t)]\n",
    "                \n",
    "                for ll in range(len(generation_times)):\n",
    "                    origins.append(in_edge)\n",
    "                    destinations.append(out_edge)\n",
    "                    gen_times.append(generation_times[ll])\n",
    "    \n",
    "    origins=np.array(origins)\n",
    "    destinations=np.array(destinations)\n",
    "    gen_times=np.array(gen_times)\n",
    "    sort_indices=np.argsort(gen_times)\n",
    "\n",
    "    # sorting is needed because SUMO assumes the trips' departure time is sorted\n",
    "    gen_times=gen_times[sort_indices]\n",
    "    origins=origins[sort_indices]\n",
    "    destinations=destinations[sort_indices]\n",
    "    \n",
    "    \n",
    "    # save the driving behavior parameters of vehicles into a dictionary, since they are not default in sumo\n",
    "    # it is also faster to access elements in dicts than in sumo\n",
    "    vehicle_ids=np.array([idx+1 for idx in range(len(gen_times))])\n",
    "\n",
    "    PTs_by_id={}\n",
    "    IDMs_by_id={}\n",
    "    types_by_id={}\n",
    "    lens_by_id={}\n",
    "    \n",
    "    trips_data=[]\n",
    "    \n",
    "    for i in range(len(vehicle_ids)):#trip in trips_data:\n",
    "        id=str(vehicle_ids[i])\n",
    "        \n",
    "        veh_type=np.random.choice([0,1,2], p=[sv_rate, av_rate, lv_rate])\n",
    "        types_by_id[id]=veh_type\n",
    "        lens_by_id[id]=(veh_type==2)*12+(veh_type!=2)*4\n",
    "\n",
    "        \n",
    "    \n",
    "        PT_cf_data=PT_param_data[int(veh_type)]\n",
    "        sample_PT=PT_cf_data.sample()[['Tmax', 'Alpha', 'Beta', 'Wc', 'Gamma1','Gamma2', 'Wm']].values[0]\n",
    "        PTs_by_id[id]=sample_PT\n",
    "    \n",
    "        IDM_cf_data=IDM_param_data[int(veh_type)]\n",
    "        sample_IDM=IDM_cf_data.sample()[['T', 'a', 'b', 'v0', 'so', \"delta\"]].values[0]\n",
    "        IDMs_by_id[id]=sample_IDM\n",
    "\n",
    "        veh={\"id\": id, \"depart\": str(round(gen_times[i],1)), \"from\": origins[i] , \"to\": destinations[i], \"type\": veh_type, \"departSpeed\":sample_IDM[3] }\n",
    "        trips_data.append(veh)\n",
    "    \n",
    "\n",
    "    root = ET.Element(\"trips\")\n",
    "\n",
    "    # Add trips to the root, which is readable by sumo\n",
    "    for trip in trips_data:\n",
    "        trip_element = ET.SubElement(root, \"trip\")\n",
    "        trip_element.set(\"id\", str(trip[\"id\"]))\n",
    "        trip_element.set(\"depart\", trip[\"depart\"])\n",
    "        trip_element.set(\"from\", trip[\"from\"])\n",
    "        trip_element.set(\"to\", trip[\"to\"])\n",
    "\n",
    "        trip_element.set(\"departLane\", \"random\") # random departure lane\n",
    "         \n",
    "        trip_element.set(\"departSpeed\", str(trip[\"departSpeed\"]))\n",
    "        \n",
    "    \n",
    "    # convert the format and save it as a trip file\n",
    "    \n",
    "    tree = ET.ElementTree(root)\n",
    "    xml_str = minidom.parseString(ET.tostring(root, 'utf-8')).toprettyxml(indent=\"  \")\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    output_file = \"configs/\"+ site +\"/\"+site+\"_trial\"+str(trial)+\".trips.xml\"\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(xml_str)\n",
    "    \n",
    "    print(f\"Trips saved to {output_file}\")\n",
    "\n",
    "    return PTs_by_id,  IDMs_by_id, types_by_id, lens_by_id, trips_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670309d-068d-4cdb-90e3-e7ee1d042459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prospect theory model\n",
    "def PT(veh_id, leader_id):\n",
    "    \n",
    "    #PTs_by_id \n",
    "    Tmax, Alpha, Beta, Wc, Gamma1,Gamma2, Wm = PTs_by_id[veh_id] # read the PT parameters for the current vehicle\n",
    "    # delta_v is speed difference\n",
    "    # gap is the leader location minus the current location minus leader length\n",
    "    # speed is the current speed of the central vehicle\n",
    "    \n",
    "    # central vehicle\n",
    "    x_a = traci.vehicle.getLanePosition(veh_id)\n",
    "    position=traci.vehicle.getPosition(veh_id)\n",
    "    v_a=traci.vehicle.getSpeed(veh_id)\n",
    "    road= traci.vehicle.getRoadID(veh_id)\n",
    "    lane= traci.vehicle.getLaneIndex(veh_id)\n",
    "\n",
    "    if leader_id!=None:\n",
    "        leader_len=lens_by_id[leader_id]\n",
    "        v_lead=traci.vehicle.getSpeed(leader_id)\n",
    "        x_lead=traci.vehicle.getLanePosition(leader_id)\n",
    "    else: # virtual vehicle needed, to be verified\n",
    "        leader_len=0\n",
    "        v_lead=v_a+0.01\n",
    "        x_lead=10000000# make it huge\n",
    "\n",
    "    veh_gap=x_lead-x_a-leader_len # gap between leader and the current vehicle\n",
    "    veh_delta_v= v_a-v_lead # speed difference  \n",
    "\n",
    "    So_D = 3 #default value by Talebpour\n",
    "    if (veh_gap - So_D) > 0.1:\n",
    "        Seff = veh_gap - So_D\n",
    "    else:\n",
    "        Seff = 0.1 #default value by Talebpour\n",
    "\n",
    "    if veh_delta_v > (Seff / Tmax):\n",
    "        Tau = Seff / veh_delta_v\n",
    "    else:\n",
    "        Tau = Tmax\n",
    "\n",
    "    if veh_delta_v == 0:\n",
    "        veh_delta_v = 0.0000001 #default value by Talebpour\n",
    "    if Alpha == 0:\n",
    "        Alpha = 0.0000001 #default value by Talebpour\n",
    "    Zprime = Tau / (2.0 * Alpha * v_a)\n",
    "    Zdoubleprime = 0.0\n",
    "\n",
    "    #if Wc * Zprime >= 1:\n",
    "    if Wc * Zprime > 0:\n",
    "        if (2.0 * math.log(Wc * Zprime)) >= 0:\n",
    "            a0 = 1\n",
    "            #Zstar = (-1 * math.sqrt(2.0 * math.log(Wc * Zprime))) / (math.sqrt(2.0 * math.pi)) #default by Talebpour\n",
    "            Zstar = -math.sqrt(2.0 * math.log((a0 * Wc * Tau) / (2.0 * math.sqrt(2.0 * math.pi) * Alpha * v_a))) #changed to be consistent with paper\n",
    "            if np.abs(Zstar) > 0.05:\n",
    "                Zstar = 0.05 #added threshold to reduce fluctuations\n",
    "    else:\n",
    "        Zstar = 0.0\n",
    "    Astar = (2.0 / Tau) * ((Seff / Tau) - veh_delta_v + (Alpha * v_a * Zstar))\n",
    "    for NewtonCounter in range(3):\n",
    "        X = Astar\n",
    "        if X >= 0:\n",
    "            if X == 0:\n",
    "                X = 0.0000001 #default value by Talebpour\n",
    "            Uptprime = Gamma1 * math.pow(X, Gamma1 - 1)\n",
    "            Uptdoubleprime = Gamma1 * (Gamma1 - 1) * math.pow(X, Gamma1 - 2)\n",
    "        else:\n",
    "            Uptprime = Wm * Gamma2 * pow(-X, Gamma2 - 1)\n",
    "            Uptdoubleprime = -Wm * Gamma2 * (Gamma2 - 1) * pow(-X, Gamma2 - 2)\n",
    "\n",
    "        Z = (veh_delta_v + (0.5 * Astar * Tau) - (Seff / Tau)) / (Alpha * veh_delta_v)\n",
    "        fn = norm.cdf(Z)\n",
    "\n",
    "        F = Uptprime - Wc * fn * Zprime\n",
    "        Fprime = Uptdoubleprime - Wc * fn * (Z * math.pow(Zprime, 2.0) + Zdoubleprime)\n",
    "        if Fprime == 0:\n",
    "            Fprime = 0.000000000001 #default value by Talebpour\n",
    "\n",
    "        Astar = Astar - (F / Fprime)\n",
    "\n",
    "    X = Astar\n",
    "    if X >= 0:\n",
    "        Uptprime = Gamma1 * math.pow(X, Gamma1 - 1)\n",
    "        Uptdoubleprime = Gamma1 * (Gamma1 - 1) * math.pow(X, Gamma1 - 2)\n",
    "    else:\n",
    "        Uptprime = Wm * Gamma2 * pow(-X, Gamma2 - 1)\n",
    "        Uptdoubleprime = -Wm * Gamma2 * (Gamma2 - 1) * pow(-X, Gamma2 - 2)\n",
    "    Z = (veh_delta_v + (0.5 * Astar * Tau) - (Seff / Tau)) / (Alpha * veh_delta_v)\n",
    "    fn = norm.cdf(Z)\n",
    "    F = Uptprime - Wc * fn * Zprime\n",
    "    Fprime = Uptdoubleprime - Wc * fn * (Z * math.pow(Zprime, 2.0) + Zdoubleprime)\n",
    "    if Fprime == 0:\n",
    "        Fprime = 0.000000000001\n",
    "\n",
    "    Var = -1.0 / (Beta * Fprime)\n",
    "\n",
    "    Random_Wiener = np.random.rand()\n",
    "    Yt = math.exp(-1 * 0.1 / Tau) + math.sqrt(24.0 * 0.1 / Tau) * Random_Wiener #default value by Talebpour\n",
    "    accl_cf = Astar + Var * Yt\n",
    "    accl_ff = accl_max * (1 - (v_a / v_desired))\n",
    "\n",
    "    accl_ = np.minimum(accl_cf, accl_ff)\n",
    "\n",
    "    if accl_ > 3: #default value by Talebpour\n",
    "        accl_ = 3\n",
    "    elif accl_ < -8: #default value by Talebpour\n",
    "        accl_ = -8\n",
    "\n",
    "    return accl_  # return acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8194a-00a8-4f51-9c29-f12a440b2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def IDM(veh_id, leader_id, leader_lane, adjust_length, x_a, v_a, lane, x_lead):\n",
    "    # input:\n",
    "    ## vehicle id, leader id, the lane segment of the leader (may not be exactly the same as the follower, since SUMo segments the lanes into segments)\n",
    "    ## adjust_length is used to adjust the distance if the lane of the leader and follower are segmented into different lane ids, since sumo returns the position within the same lane index\"\n",
    "    ### it is the remaining distance in the follower's lane index added with the lengths of the links skipped\n",
    "    ## x_a v_a is the position of the follower within its lane segment and its speed\n",
    "    ## lane is the lane index of the follower\n",
    "    # x_lead is the leader position within its lane\n",
    "    idm_params=IDMs_by_id[veh_id]\n",
    "    T, a, b, v0, s0, delta = idm_params # include error term as well potentially\n",
    "    \n",
    "    if leader_id==None:\n",
    "        acc=a*(1-(v_a/v0)**delta)\n",
    "    elif lane==leader_lane: # same lane segment\n",
    "        leader_len=lens_by_id[leader_id]\n",
    "        veh_len=lens_by_id[veh_id]\n",
    "        v_lead=traci.vehicle.getSpeed(leader_id)\n",
    "        x_lead=traci.vehicle.getLanePosition(leader_id)\n",
    "        s_star=s0+v_a*T + v_a*(v_a-v_lead)/(2*np.sqrt(a*b))\n",
    "        acc=a*(1-(v_a/v0)**delta-(s_star/(x_lead-x_a-0.5*(leader_len+veh_len)))**2)\n",
    "    else: # different lane, use absolute distance\n",
    "        leader_len=lens_by_id[leader_id]\n",
    "        veh_len=lens_by_id[veh_id]\n",
    "        v_lead=traci.vehicle.getSpeed(leader_id)\n",
    "        s_star=s0+v_a*T + v_a*(v_a-v_lead)/(2*np.sqrt(a*b))\n",
    "        acc=a*(1-(v_a/v0)**delta-(s_star/(x_lead+adjust_length-0.5*(leader_len+veh_len)))**2)\n",
    "\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ec8b6-b3c6-4a34-9896-13a549c16b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c745b-53ba-4d9b-82ee-fa53ee55591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are not visualizing\n",
    "\n",
    "#@ray.remote # need this if it is run remotely. Fine otherwise\n",
    "def run_simulation(inputs):\n",
    "    trial=inputs[0]\n",
    "    PTs_by_id=inputs[1]\n",
    "    IDMs_by_id=inputs[2]\n",
    "    types_by_id=inputs[3]\n",
    "    lens_by_id=inputs[4]\n",
    "    trips_data=inputs[5]\n",
    "    is_generated={} # whether the vehicles in the trip file are generated\n",
    "    for idx in lens_by_id:\n",
    "       is_generated[idx]=False \n",
    "    \n",
    "    sumo_binary = checkBinary('sumo-gui') # do \n",
    "    sim_time=max_t\n",
    "    config_file = \"configs/\"+site+\"/\"+site+\"_trial\"+str(trial)+\".sumocfg\" # read the configuration file\n",
    "\n",
    "    # initialize the data collection dictionary\n",
    "    all_vehs={\"time\":[], \"veh_id\":[], \"type\":[], \"length\":[],  \"x\":[], \"y\":[], \"v\":[], \"road\":[], \"lane\":[], \"lane_pos\":[] } # characteristics of vehicles of each step size appended into pd dataframe\n",
    "    \n",
    "    print(\"sim_t\", sim_time)\n",
    "\n",
    "    # start the simulation\n",
    "    traci.start([sumo_binary, \"-c\", config_file], verbose=False, label=str(trial))  # Starts the simulation\n",
    "\n",
    "    step = 0\n",
    "    lane_lens={lane: traci.lane.getLength(lane) for lane in traci.lane.getIDList()}\n",
    "    \n",
    "    while step < int(sim_time/step_size):  # Run the simulation for 3600 seconds (1 hour), which is 36000 steps\n",
    "        if step*step_size%100==0:\n",
    "            print(step*step_size)\n",
    "        \n",
    "        # vehicle ids\n",
    "        veh_ids=traci.vehicle.getIDList()\n",
    "\n",
    "\n",
    "        # dictionary to append new speeds and lanes when calculated\n",
    "        # it will be updated in SUMO once all the vehicles have been calculated\n",
    "        \n",
    "        new_speeds={} # make sure there is no sequence effect\n",
    "        new_lanes={} # the new lane choice of vehicles\n",
    "        veh_ids_by_lane={} # vehicle ids in one lane\n",
    "        \n",
    "        for veh_id in veh_ids:\n",
    "            \n",
    "            \n",
    "            if is_generated[veh_id]==False: # only set when the vehicles are first step generation\n",
    "                traci.vehicle.setParameter(veh_id, \"lcTimeToLat\", \"2.0\")\n",
    "                traci.vehicle.setLength(veh_id, lens_by_id[veh_id]) \n",
    "                is_generated[veh_id]=True\n",
    "            \n",
    "            x_a = traci.vehicle.getLanePosition(veh_id)\n",
    "            position=traci.vehicle.getPosition(veh_id)\n",
    "            lane_pos=traci.vehicle.getLanePosition(veh_id)\n",
    "            v_a=traci.vehicle.getSpeed(veh_id)\n",
    "            road= traci.vehicle.getRoadID(veh_id)\n",
    "            lane= traci.vehicle.getLaneIndex(veh_id)\n",
    "\n",
    "            # append the data in sumo into collected data\n",
    "            all_vehs[\"time\"].append(step*step_size)\n",
    "            all_vehs[\"veh_id\"].append(veh_id)\n",
    "            all_vehs[\"x\"].append(position[0])\n",
    "            all_vehs[\"y\"].append(position[1])\n",
    "            all_vehs[\"v\"].append(v_a)\n",
    "            all_vehs[\"road\"].append(road)\n",
    "            all_vehs[\"lane\"].append((road)+\"_\"+str(lane))\n",
    "            all_vehs[\"lane_pos\"].append(lane_pos)\n",
    "            all_vehs[\"type\"].append(types_by_id[veh_id])\n",
    "            all_vehs[\"length\"].append(lens_by_id[veh_id])\n",
    "            \n",
    "            \n",
    "            leader_id=traci.vehicle.getLeader(veh_id) # need to be obtained here\n",
    "            next_lane=(road)+\"_\"+str(lane) # initialize as the current lane\n",
    "            \n",
    "            \n",
    "            # find the leader (since it may not have the same lane index as the follower)\n",
    "            adjust_length= lane_lens[next_lane] - traci.vehicle.getLanePosition(veh_id) #traci.lane.getLength(next_lane)-traci.vehicle.getLanePosition(veh_id) \n",
    "            forward_count=0\n",
    "            most_upstream_dist=None\n",
    "            \n",
    "            while leader_id==None and next_lanes_dict[next_lane]!=None and forward_count<3 and adjust_length<500 :\n",
    "                forward_count=forward_count+1\n",
    "                \n",
    "                next_lane=next_lanes_dict[next_lane]\n",
    "                if not next_lane in veh_ids_by_lane:\n",
    "                    next_ids=traci.lane.getLastStepVehicleIDs(next_lane)\n",
    "                    veh_ids_by_lane[next_lane]=next_ids\n",
    "                else:\n",
    "                    next_ids=veh_ids_by_lane[next_lane]\n",
    "                 \n",
    "                if len(next_ids)==0: # the next lane has 0 vehicles\n",
    "                    adjust_length=adjust_length+lane_lens[next_lane]#traci.lane.getLength(next_lane) # the lane is skipped, so add up the length of it\n",
    "                    continue\n",
    "                \n",
    "                most_upstream_id = min(next_ids, key=lambda vid: traci.vehicle.getLanePosition(vid))\n",
    "                most_upstream_dist = traci.vehicle.getLanePosition(most_upstream_id)\n",
    "                leader_id=[most_upstream_id]\n",
    "                \n",
    "            leader_lane=next_lane       \n",
    "\n",
    "            if leader_id is not None:\n",
    "                leader_id=leader_id[0]\n",
    "                leader_len=lens_by_id[leader_id]\n",
    "\n",
    "            # customize car follow model\n",
    "            if cf_model==\"IDM\": # for IDM\n",
    "                acc=IDM(veh_id, leader_id, leader_lane, adjust_length, x_a, v_a, road, (road)+\"_\"+str(lane), most_upstream_dist)\n",
    "                new_speeds[veh_id]=v_a+acc*step_size#max(v_a+acc*step_size, 0) # changed here\n",
    "\n",
    "            if cf_model==\"PT\" or cf_model==\"Prospect Theory\": # for PT\n",
    "                # implement prospect theory here\n",
    "                acc=PT(veh_id, leader_id)\n",
    "                new_speeds[veh_id]=max(v_a+acc*step_size, 0)\n",
    "            \n",
    "        for veh_id in veh_ids:\n",
    "            traci.vehicle.setSpeed(veh_id, new_speeds[veh_id])\n",
    "\n",
    "\n",
    "        for veh_id in veh_ids:\n",
    "            # to do: update the lane of the vehicles \n",
    "\n",
    "            \n",
    "        traci.simulationStep()  # Advance one simulation step\n",
    "        step += 1\n",
    "    \n",
    "    traci.close()  # Close the simulation\n",
    "\n",
    "    return all_vehs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05f022-fc2a-4b94-a222-8f527ab3a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the site\n",
    "site_idx=3\n",
    "sites={1:\"I90_94\", 2:\"I294\", 3:\"I395\" }\n",
    "site=sites[site_idx]\n",
    "\n",
    "\n",
    "min_hw=0.1 # the minimum headway between vehicles during vehicle generation. Not sure if this is needed\n",
    "# the min and max sim time\n",
    "min_t=0\n",
    "max_t=1200 # change this for a different simulation time\n",
    "\n",
    "# simulation step size\n",
    "step_size=0.1\n",
    "\n",
    "# Model selection\n",
    "cf_model_choice=1\n",
    "cf_models = {1:\"IDM\", 2:\"PT\"} # car following model\n",
    "\n",
    "# number_of trails\n",
    "num_trials = 1\n",
    "\n",
    "# warm up time among which data will not be collected\n",
    "warm_up_t=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the parameter of the scenarios: [av_rate, lv_rate, flow_main, flow_ramp_to_ramp, flow_ramp_to_main, flow_main_to_ramp, cf_model_choice]# \n",
    "# feel free to run all of them\n",
    "all_scenarios=[[0.3, 0.2, 6000, 500, 500, 500, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1b46c-b437-439e-8fc3-9ac4c51d96a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one at a time\n",
    "# make sure no ray module before the function\n",
    "#'''\n",
    "for scenarios in all_scenarios:\n",
    "    print(scenarios)\n",
    "    av_rate, lv_rate, flow_main, flow_ramp_to_ramp, flow_ramp_to_main, flow_main_to_ramp, cf_model_choice = scenarios\n",
    "    sv_rate=1-av_rate-lv_rate\n",
    "    cf_model= cf_models[cf_model_choice]\n",
    "    inputs_all_trial=[]\n",
    "    od_demand, all_edges, in_edges, out_edges, first_exit, first_exit_start_lane, next_lanes_dict=initialize()\n",
    "    for trial in range(0,num_trials): # number of trials, we can simulate multiple trials\n",
    "        print(\"trial\", trial)\n",
    "        PTs_by_id,  IDMs_by_id, types_by_id, lens_by_id, trips_data= generate_vehicles(trial)\n",
    "        inputs_all_trial.append([trial, PTs_by_id,  IDMs_by_id, types_by_id, lens_by_id, trips_data])\n",
    "        \n",
    "        \n",
    "    vehs_all_trials=[run_simulation_default(inputs) for inputs in inputs_all_trial]\n",
    "    \n",
    "    for trial in range(0,1):\n",
    "        all_vehs=pd.DataFrame(vehs_all_trials[trial])\n",
    "        # save the collected vehicle data\n",
    "        all_vehs.to_csv(\"trajs_\"+site+\"_\"+str(scenarios)+\"_trial\"+str(trial)+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cb681-9ea5-4307-a0fc-068e8ce20070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
